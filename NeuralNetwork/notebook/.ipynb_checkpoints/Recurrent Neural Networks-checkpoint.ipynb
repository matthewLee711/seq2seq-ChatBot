{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks\n",
    "\n",
    "Importance of understanding neural networks:\n",
    "\n",
    "Basics of machine learning, linear algebra, neural network architecture, cost functions, optimization methods, training/test sets, activation functions/what they do, softmax\n",
    "\n",
    "What are recurrent neural networks:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can RNN do that ANN cannot?\n",
    "\n",
    "Image captioning, language translation, sentiment classification, predictive typing, video classification, nlp, speech recognition, etc.\n",
    "\n",
    "Feed forward NN are strong global function approximators. In other words, you can have a very difficult classification function and the FFNN can figure out the generaltivity(lol) of it. Recurrent neural networks take this to another level and instead they cam compute/describe an entire program. They can almost be considered turing complete (system in which a program can be used to solve any computation problem).\n",
    "- ANN cannot deal with sequential or temporal data (because of weighted matrix and fixed input/output size)\n",
    "- ANN lack memory (Cannot store past results)\n",
    "- ANN have a fixed architecture (Have to change the nn and re-train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
